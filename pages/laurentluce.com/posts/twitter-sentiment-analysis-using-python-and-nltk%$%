<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
<title>  Twitter sentiment analysis using Python and NLTK | Laurent Luce&#039;s Blog</title>
<meta name="description" content="  Twitter sentiment analysis using Python and NLTK" />
<meta name="keywords" content="  Twitter sentiment analysis using Python and NLTK" />
<link rel="stylesheet" type="text/css" href="http://www.laurentluce.com/wp-content/themes/openark-blog/style.css" media="screen" />
<link rel="alternate" type="application/rss+xml" title="RSS 2.0" href="http://www.laurentluce.com/feed/" />
<link rel="pingback" href="http://www.laurentluce.com/xmlrpc.php" />

            <script type="text/javascript">//<![CDATA[
            // Google Analytics for WordPress by Yoast v4.3.3 | http://yoast.com/wordpress/google-analytics/
            var _gaq = _gaq || [];
            _gaq.push(['_setAccount', 'UA-12599046-1']);
				            _gaq.push(['_trackPageview']);
            (function () {
                var ga = document.createElement('script');
                ga.type = 'text/javascript';
                ga.async = true;
                ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';

                var s = document.getElementsByTagName('script')[0];
                s.parentNode.insertBefore(ga, s);
            })();
            //]]></script>
			<link rel="alternate" type="application/rss+xml" title="Laurent Luce&#039;s Blog &raquo; Twitter sentiment analysis using Python and NLTK Comments Feed" href="http://www.laurentluce.com/posts/twitter-sentiment-analysis-using-python-and-nltk/feed/" />
<script type='text/javascript' src='http://www.laurentluce.com/wp-includes/js/jquery/jquery.js?ver=1.11.0'></script>
<script type='text/javascript' src='http://www.laurentluce.com/wp-includes/js/jquery/jquery-migrate.min.js?ver=1.2.1'></script>
<link rel="EditURI" type="application/rsd+xml" title="RSD" href="http://www.laurentluce.com/xmlrpc.php?rsd" />
<link rel="wlwmanifest" type="application/wlwmanifest+xml" href="http://www.laurentluce.com/wp-includes/wlwmanifest.xml" /> 
<link rel='prev' title='Python dictionary implementation' href='http://www.laurentluce.com/posts/python-dictionary-implementation/' />
<link rel='next' title='Python, Twitter statistics and the 2012 French presidential election' href='http://www.laurentluce.com/posts/python-twitter-statistics-and-the-2012-french-presidential-election/' />
<meta name="generator" content="WordPress 3.9.1" />
<link rel='canonical' href='http://www.laurentluce.com/posts/twitter-sentiment-analysis-using-python-and-nltk/' />
<link rel='shortlink' href='http://www.laurentluce.com/?p=321' />
<style type="text/css" id="syntaxhighlighteranchor"></style>
</head>

<body>
<div align="center">
<div id="wrapper">
<div id="doc1" class="yui-t4">
<div id="hd">
	<div id="sitemeta">
		<ul>
     			     			<li><a href="http://www.laurentluce.com/wp-login.php">Log in</a></li>
     			     			<li class="rss"><a href="http://www.laurentluce.com/feed/">Subscribe RSS Feed</a></li>
  		</ul>
	</div>
	<div id="titlewrapper">
		<div id="blogtitle">
			<h1><a href="http://www.laurentluce.com/">Laurent Luce&#039;s Blog</a></h1>
		</div>
		<div id="menu">
			<ul>
				<li><div id="blogdescription">Technical blog on web technologies</div></li>
				<li><a href="http://www.laurentluce.com/">Home</a></li>
				<li class="page_item page-item-2"><a href="http://www.laurentluce.com/about/">About</a></li>
			</ul>
		</div>
	</div>
	<div id="newsflash">
                
	</div>
	<div class="clear">&nbsp;</div>
</div>

<div id="sidebar" class="yui-b">
<ul class="sidebar">
		<li id="recent-posts-4" class="widget widget_recent_entries">		<h2 class="widgettitle">Recent Posts</h2>
		<ul>
					<li>
				<a href="http://www.laurentluce.com/posts/cambridge-city-geospatial-statistics/">Cambridge city geospatial statistics</a>
						</li>
					<li>
				<a href="http://www.laurentluce.com/posts/api-to-access-the-cambridge-city-geospatial-data/">API to access the Cambridge city geospatial data</a>
						</li>
					<li>
				<a href="http://www.laurentluce.com/posts/rest-service-python-client-to-access-geographic-data/">REST service + Python client to access geographic data</a>
						</li>
					<li>
				<a href="http://www.laurentluce.com/posts/massachusetts-census-2010-towns-maps-and-statistics-using-python/">Massachusetts Census 2010 Towns maps and statistics using Python</a>
						</li>
					<li>
				<a href="http://www.laurentluce.com/posts/python-twitter-statistics-and-the-2012-french-presidential-election/">Python, Twitter statistics and the 2012 French presidential election</a>
						</li>
					<li>
				<a href="http://www.laurentluce.com/posts/twitter-sentiment-analysis-using-python-and-nltk/">Twitter sentiment analysis using Python and NLTK</a>
						</li>
					<li>
				<a href="http://www.laurentluce.com/posts/python-dictionary-implementation/">Python dictionary implementation</a>
						</li>
					<li>
				<a href="http://www.laurentluce.com/posts/python-string-objects-implementation/">Python string objects implementation</a>
						</li>
					<li>
				<a href="http://www.laurentluce.com/posts/python-integer-objects-implementation/">Python integer objects implementation</a>
						</li>
					<li>
				<a href="http://www.laurentluce.com/posts/python-and-cryptography-with-pycrypto/">Python and cryptography with pycrypto</a>
						</li>
				</ul>
		</li>
<li id="search-3" class="widget widget_search"><h2 class="widgettitle">Search</h2>
<form method="get" id="searchform" action="http://www.laurentluce.com/">
<input type="text" size="14" value="" name="s" id="s" class="s" />
<input type="submit" id="searchsubmit" value="GO" />
</form></li>
<li id="meta-3" class="widget widget_meta"><h2 class="widgettitle">Meta</h2>
			<ul>
						<li><a href="http://www.laurentluce.com/wp-login.php">Log in</a></li>
			<li><a href="http://www.laurentluce.com/feed/" title="Syndicate this site using RSS 2.0">Entries <abbr title="Really Simple Syndication">RSS</abbr></a></li>
			<li><a href="http://www.laurentluce.com/comments/feed/" title="The latest comments to all posts in RSS">Comments <abbr title="Really Simple Syndication">RSS</abbr></a></li>
<li><a href="https://wordpress.org/" title="Powered by WordPress, state-of-the-art semantic personal publishing platform.">WordPress.org</a></li>			</ul>
</li>
</ul>
</div>

<div id="bd" class="single">
<div id="yui-main"><div class="yui-b">
	<div class="post-wrap" id="post">
		<h1 class="post-title"><a href="http://www.laurentluce.com/posts/twitter-sentiment-analysis-using-python-and-nltk/" rel="bookmark" title="Permanent Link to Twitter sentiment analysis using Python and NLTK">Twitter sentiment analysis using Python and NLTK</a></h1>
	                <div>January 2, 2012</div> 
			<div class="story-content">
			<p>This post describes the implementation of sentiment analysis of tweets using Python and the natural language toolkit <a href="http://www.nltk.org">NLTK</a>. The post also describes the internals of NLTK related to this implementation.</p>
<h2>Background</h2>
<p>The purpose of the implementation is to be able to automatically classify a tweet as a positive or negative tweet sentiment wise.</p>
<p>The classifier needs to be trained and to do that, we need a list of manually classified tweets. Let&#8217;s start with 5 positive tweets and 5 negative tweets.</p>
<p>Positive tweets:</p>
<ul>
<li>I love this car.</li>
<li>This view is amazing.</li>
<li>I feel great this morning.</li>
<li>I am so excited about the concert.</li>
<li>He is my best friend.</li>
</ul>
<p>Negative tweets:</p>
<ul>
<li>I do not like this car.</li>
<li>This view is horrible.</li>
<li>I feel tired this morning.</li>
<li>I am not looking forward to the concert.</li>
<li>He is my enemy.</li>
</ul>
<p>In the full implementation, I use about 600 positive tweets and 600 negative tweets to train the classifier. I store those tweets in a Redis DB. Even with those numbers, it is quite a small sample and you should use a much larger set if you want good results.</p>
<p>Next is a test set so we can assess the exactitude of the trained classifier.</p>
<p>Test tweets:</p>
<ul>
<li>I feel happy this morning. positive.</li>
<li>Larry is my friend. positive.</li>
<li>I do not like that man. negative.</li>
<li>My house is not great. negative.</li>
<li>Your song is annoying. negative.</li>
</ul>
<h2>Implementation</h2>
<p>The following list contains the positive tweets:</p>
<pre class="brush: python; title: ; notranslate" title="">
pos_tweets = [('I love this car', 'positive'),
              ('This view is amazing', 'positive'),
              ('I feel great this morning', 'positive'),
              ('I am so excited about the concert', 'positive'),
              ('He is my best friend', 'positive')]
</pre>
<p>The following list contains the negative tweets:</p>
<pre class="brush: python; title: ; notranslate" title="">
neg_tweets = [('I do not like this car', 'negative'),
              ('This view is horrible', 'negative'),
              ('I feel tired this morning', 'negative'),
              ('I am not looking forward to the concert', 'negative'),
              ('He is my enemy', 'negative')]
</pre>
<p>We take both of those lists and create a single list of tuples each containing two elements. First element is an array containing the words and second element is the type of sentiment. We get rid of the words smaller than 2 characters and we use lowercase for everything. </p>
<pre class="brush: python; title: ; notranslate" title="">
tweets = []
for (words, sentiment) in pos_tweets + neg_tweets:
    words_filtered = [e.lower() for e in words.split() if len(e) &gt;= 3] 
    tweets.append((words_filtered, sentiment))
</pre>
<p>The list of tweets now looks like this:</p>
<pre class="brush: python; title: ; notranslate" title="">
tweets = [
    (['love', 'this', 'car'], 'positive'),
    (['this', 'view', 'amazing'], 'positive'),
    (['feel', 'great', 'this', 'morning'], 'positive'),
    (['excited', 'about', 'the', 'concert'], 'positive'),
    (['best', 'friend'], 'positive'),
    (['not', 'like', 'this', 'car'], 'negative'),
    (['this', 'view', 'horrible'], 'negative'),
    (['feel', 'tired', 'this', 'morning'], 'negative'),
    (['not', 'looking', 'forward', 'the', 'concert'], 'negative'),
    (['enemy'], 'negative')]
</pre>
<p>Finally, the list with the test tweets:</p>
<pre class="brush: python; title: ; notranslate" title="">
test_tweets = [
    (['feel', 'happy', 'this', 'morning'], 'positive'),
    (['larry', 'friend'], 'positive'),
    (['not', 'like', 'that', 'man'], 'negative'),
    (['house', 'not', 'great'], 'negative'),
    (['your', 'song', 'annoying'], 'negative')]
</pre>
<h2>Classifier</h2>
<p>The list of word features need to be extracted from the tweets. It is a list with every distinct words ordered by frequency of appearance. We use the following function to get the list plus the two helper functions.</p>
<pre class="brush: python; title: ; notranslate" title="">
word_features = get_word_features(get_words_in_tweets(tweets))
</pre>
<pre class="brush: python; title: ; notranslate" title="">
def get_words_in_tweets(tweets):
    all_words = []
    for (words, sentiment) in tweets:
      all_words.extend(words)
    return all_words
</pre>
<pre class="brush: python; title: ; notranslate" title="">
def get_word_features(wordlist):
    wordlist = nltk.FreqDist(wordlist)
    word_features = wordlist.keys()
    return word_features
</pre>
<p>If we take a pick inside the function get_word_features, the variable &#8216;wordlist&#8217; contains:</p>
<pre class="brush: python; title: ; notranslate" title="">
&lt;FreqDist:
    'this': 6,
    'car': 2,
    'concert': 2,
    'feel': 2,
    'morning': 2,
    'not': 2,
    'the': 2,
    'view': 2,
    'about': 1,
    'amazing': 1,
    ...
&gt;
</pre>
<p>We end up with the following list of word features:</p>
<pre class="brush: python; title: ; notranslate" title="">
word_features = [
    'this',
    'car',
    'concert',
    'feel',
    'morning',
    'not',
    'the',
    'view',
    'about',
    'amazing',
    ...
]
</pre>
<p>As you can see, &#8216;this&#8217; is the most used word in our tweets, followed by &#8216;car&#8217;, followed by &#8216;concert&#8217;&#8230;</p>
<p>To create a classifier, we need to decide what features are relevant. To do that, we first need a feature extractor. The one we are going to use returns a dictionary indicating what words are contained in the input passed. Here, the input is the tweet. We use the word features list defined above along with the input to create the dictionary.</p>
<pre class="brush: python; title: ; notranslate" title="">
def extract_features(document):
    document_words = set(document)
    features = {}
    for word in word_features:
        features['contains(%s)' % word] = (word in document_words)
    return features
</pre>
<p>As an example, let&#8217;s call the feature extractor with the document ['love', 'this', 'car'] which is the first positive tweet. We obtain the following dictionary which indicates that the document contains the words: &#8216;love&#8217;, &#8216;this&#8217; and &#8216;car&#8217;.</p>
<pre class="brush: python; title: ; notranslate" title="">
{'contains(not)': False,
 'contains(view)': False,
 'contains(best)': False,
 'contains(excited)': False,
 'contains(morning)': False,
 'contains(about)': False,
 'contains(horrible)': False,
 'contains(like)': False,
 'contains(this)': True,
 'contains(friend)': False,
 'contains(concert)': False,
 'contains(feel)': False,
 'contains(love)': True,
 'contains(looking)': False,
 'contains(tired)': False,
 'contains(forward)': False,
 'contains(car)': True,
 'contains(the)': False,
 'contains(amazing)': False,
 'contains(enemy)': False,
 'contains(great)': False}
</pre>
<p>With our feature extractor, we can apply the features to our classifier using the method <a href="http://nltk.googlecode.com/svn/trunk/doc/api/nltk.classify.util-module.html#apply_features">apply_features</a>. We pass the feature extractor along with the tweets list defined above.</p>
<pre class="brush: python; title: ; notranslate" title="">
training_set = nltk.classify.apply_features(extract_features, tweets)
</pre>
<p>The variable &#8216;training_set&#8217; contains the labeled feature sets. It is a list of tuples which each tuple containing the feature dictionary and the sentiment string for each tweet. The sentiment string is also called &#8216;label&#8217;.</p>
<pre class="brush: python; title: ; notranslate" title="">
[({'contains(not)': False,
   ...
   'contains(this)': True,
   ...
   'contains(love)': True,
   ...
   'contains(car)': True,
   ...
   'contains(great)': False},
  'positive'),
 ({'contains(not)': False,
   'contains(view)': True,
   ...
   'contains(this)': True,
   ...
   'contains(amazing)': True,
   ...
   'contains(enemy)': False,
   'contains(great)': False},
  'positive'),
  ...]
</pre>
<p>Now that we have our training set, we can train our classifier.</p>
<pre class="brush: python; title: ; notranslate" title="">
classifier = nltk.NaiveBayesClassifier.train(training_set)
</pre>
<p>Here is a summary of what we just saw:</p>
<p><img src="/images/blog/nltk/overview.png" alt="Twitter sentiment analysis with Python and NLTK"></p>
<p>The <a href="http://nltk.googlecode.com/svn/trunk/doc/api/nltk.classify.naivebayes.NaiveBayesClassifier-class.html">Naive Bayes classifier</a> uses the prior probability of each label which is the frequency of each label in the training set, and the contribution from each feature. In our case, the frequency of each label is the same for &#8216;positive&#8217; and &#8216;negative&#8217;. The word &#8216;amazing&#8217; appears in 1 of 5 of the positive tweets and none of the negative tweets. This means that the likelihood of the &#8216;positive&#8217; label will be multiplied by 0.2 when this word is seen as part of the input. </p>
<p>Let&#8217;s take a look inside the classifier train method in the source code of the NLTK library. &#8216;label_probdist&#8217; is the prior probability of each label and &#8216;feature_probdist&#8217; is the feature/value probability dictionary. Those two probability objects are used to create the classifier.</p>
<pre class="brush: python; title: ; notranslate" title="">
def train(labeled_featuresets, estimator=ELEProbDist):
    ...
    # Create the P(label) distribution
    label_probdist = estimator(label_freqdist)
    ...
    # Create the P(fval|label, fname) distribution
    feature_probdist = {}
    ...
    return NaiveBayesClassifier(label_probdist, feature_probdist)
</pre>
<p>In our case, the probability of each label is 0.5 as we can see below. label_probdist is of type <a href="http://nltk.googlecode.com/svn/trunk/doc/api/nltk.probability.ELEProbDist-class.html">ELEProbDist</a>.</p>
<pre class="brush: python; title: ; notranslate" title="">
print label_probdist.prob('positive')
0.5
print label_probdist.prob('negative')
0.5
</pre>
<p>The feature/value probability dictionary associates expected likelihood estimate to a feature and label. We can see that the probability for the input to be negative is about 0.077 when the input contains the word &#8216;best&#8217;.</p>
<pre class="brush: python; title: ; notranslate" title="">
print feature_probdist
{('negative', 'contains(view)'): &lt;ELEProbDist based on 5 samples&gt;,
 ('positive', 'contains(excited)'): &lt;ELEProbDist based on 5 samples&gt;,
 ('negative', 'contains(best)'): &lt;ELEProbDist based on 5 samples&gt;, ...}
print feature_probdist[('negative', 'contains(best)')].prob(True)
0.076923076923076927
</pre>
<p>We can display the most informative features for our classifier using the method <a href="http://nltk.googlecode.com/svn/trunk/doc/api/nltk.classify.naivebayes.NaiveBayesClassifier-class.html#show_most_informative_features">show_most_informative_features</a>. Here, we see that if the input does not contain the word &#8216;not&#8217; then the positive ration is 1.6. </p>
<pre class="brush: python; title: ; notranslate" title="">
print classifier.show_most_informative_features(32)
Most Informative Features
           contains(not) = False          positi : negati =      1.6 : 1.0
         contains(tired) = False          positi : negati =      1.2 : 1.0
       contains(excited) = False          negati : positi =      1.2 : 1.0
         contains(great) = False          negati : positi =      1.2 : 1.0
       contains(looking) = False          positi : negati =      1.2 : 1.0
          contains(like) = False          positi : negati =      1.2 : 1.0
          contains(love) = False          negati : positi =      1.2 : 1.0
       contains(amazing) = False          negati : positi =      1.2 : 1.0
         contains(enemy) = False          positi : negati =      1.2 : 1.0
         contains(about) = False          negati : positi =      1.2 : 1.0
          contains(best) = False          negati : positi =      1.2 : 1.0
       contains(forward) = False          positi : negati =      1.2 : 1.0
        contains(friend) = False          negati : positi =      1.2 : 1.0
      contains(horrible) = False          positi : negati =      1.2 : 1.0
...
</pre>
<h2>Classify</h2>
<p>Now that we have our classifier initialized, we can try to classify a tweet and see what the sentiment type output is. Our classifier is able to detect that this tweet has a positive sentiment because of the word &#8216;friend&#8217; which is associated to the positive tweet &#8216;He is my best friend&#8217;. </p>
<pre class="brush: python; title: ; notranslate" title="">
tweet = 'Larry is my friend'
print classifier.classify(extract_features(tweet.split()))
positive
</pre>
<p>Let&#8217;s take a look at how the <a href="http://nltk.googlecode.com/svn/trunk/doc/api/nltk.classify.naivebayes.NaiveBayesClassifier-class.html#classify">classify</a> method works internally in the NLTK library. What we pass to the classify method is the feature set of the tweet we want to analyze. The feature set dictionary indicates that the tweet contains the word &#8216;friend&#8217;.</p>
<pre class="brush: python; title: ; notranslate" title="">
print extract_features(tweet.split())
{'contains(not)': False,
 'contains(view)': False,
 'contains(best)': False,
 'contains(excited)': False,
 'contains(morning)': False,
 'contains(about)': False,
 'contains(horrible)': False,
 'contains(like)': False,
 'contains(this)': False,
 'contains(friend)': True,
 'contains(concert)': False,
 'contains(feel)': False,
 'contains(love)': False,
 'contains(looking)': False,
 'contains(tired)': False,
 'contains(forward)': False,
 'contains(car)': False,
 'contains(the)': False,
 'contains(amazing)': False,
 'contains(enemy)': False,
 'contains(great)': False}
</pre>
<pre class="brush: python; title: ; notranslate" title="">
def classify(self, featureset):
    # Discard any feature names that we've never seen before.
    # Find the log probability of each label, given the features.
    # Then add in the log probability of features given labels.
    # Generate a probability distribution dictionary using the dict logprod
    # Return the sample with the greatest probability from the probability
    # distribution dictionary
</pre>
<p>Let&#8217;s go through that method using our example. The parameter passed to the method classify is the feature set dictionary we saw above. The first step is to discard any feature names that are not know by the classifier. This step does nothing in our case so the feature set stays the same.</p>
<p>Next step is to find the log probability for each label. The probability of each label (&#8216;positive&#8217; and &#8216;negative&#8217;) is 0.5. The log probability is the log base 2 of that which is -1. We end up with logprod containing the following:</p>
<pre class="brush: python; title: ; notranslate" title="">
{'positive': -1.0, 'negative': -1.0}
</pre>
<p>The log probability of features given labels is then added to logprod. This means that for each label, we go through the items in the feature set and we add the log probability of each item to logprod[label]. For example, we have the feature name &#8216;friend&#8217; and the feature value True. Its log probability for the label &#8216;positive&#8217; in our classifier is -2.12. This value is added to logprod['positive']. We end up with the following logprod dictionary.</p>
<pre class="brush: python; title: ; notranslate" title="">
{'positive': -5.4785441837188511, 'negative': -14.784261334886439}
</pre>
<p>The probability distribution dictionary of type <a href="http://nltk.googlecode.com/svn/trunk/doc/api/nltk.probability.DictionaryProbDist-class.html">DictionaryProbDist</a> is generated:</p>
<pre class="brush: python; title: ; notranslate" title="">
DictionaryProbDist(logprob, normalize=True, log=True)
</pre>
<p>The label with the greatest probability is returned which is &#8216;positive&#8217;. Our classifier finds out that this tweets has a positive sentiment based on the training we did.</p>
<p>Another example is the tweet &#8216;My house is not great&#8217;. The word &#8216;great&#8217; weights more on the positive side but the word &#8216;not&#8217; is part of two negative tweets in our training set so the output from the classifier is &#8216;negative&#8217;. Of course, the following tweet: &#8216;The movie is not bad&#8217; would return &#8216;negative&#8217; even if it is &#8216;positive&#8217;. Again, a large and well chosen sample will help with the accuracy of the classifier.</p>
<p>Taking the following test tweet &#8216;Your song is annoying&#8217;. The classifier thinks it is positive. The reason is that we don&#8217;t have any information on the feature name &#8216;annoying&#8217;. Larger the training sample tweets is, better the classifier will be.</p>
<pre class="brush: python; title: ; notranslate" title="">
tweet = 'Your song is annoying'
print classifier.classify(extract_features(tweet.split()))
positive
</pre>
<p>There is an <a href="http://nltk.googlecode.com/svn/trunk/doc/api/nltk.classify.util-module.html#accuracy">accuracy</a> method we can use to check the quality of our classifier by using our test tweets. We get 0.8 in our case which is high because we picked our test tweets for this article. The key is to have a very large number of manually classified positive and negative tweets.</p>
<p>Voilà. Don&#8217;t hesitate to post a comment if you have any feedback.</p>
			</div><!-- end post content -->
		<div class="metawrap">
		<p>
			tags: <a href="http://www.laurentluce.com/posts/tag/python/" rel="tag">Python</a><br />			posted in <a href="http://www.laurentluce.com/posts/category/uncategorized/" title="View all posts in Uncategorized" rel="category tag">Uncategorized</a> by Laurent Luce					</p>

		<p class="interact"> Follow comments via the <a href='http://www.laurentluce.com/posts/twitter-sentiment-analysis-using-python-and-nltk/feed/'>RSS Feed</a> | <a href="#respond">Leave a comment</a> | <a href="http://www.laurentluce.com/posts/twitter-sentiment-analysis-using-python-and-nltk/trackback/">Trackback URL</a> </p>
		</div><!-- end meta wrap -->
	</div><!-- end post -->

<!-- You can start editing here. -->
<div id="commentwrap">
<h3 id="comments">36 Comments to "Twitter sentiment analysis using Python and NLTK"</h3>
	
	<ol id="commentlist">
					<li class="alt" id="comment-10087">
			<p><img alt='' src='http://1.gravatar.com/avatar/b98960747cc2dcdcd27675921c338d8f?s=32&amp;d=http%3A%2F%2F1.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D32&amp;r=G' class='avatar avatar-32 photo' height='32' width='32' /><cite>Koray Sahinoglu</cite> wrote:</p>
			<p>Very nice example with detailed explanations. Good work, thank you.</p>
						<p class="commentmetadata"><a href="#comment-10087" title="">Link</a> | January 2nd, 2012 at 11:16 pm </p>
		</li>
					<li class="" id="comment-10097">
			<p><img alt='' src='http://1.gravatar.com/avatar/ba27dd571b1ba2f34cac069d4778d4e6?s=32&amp;d=http%3A%2F%2F1.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D32&amp;r=G' class='avatar avatar-32 photo' height='32' width='32' /><cite>Patrick</cite> wrote:</p>
			<p>Hi,<br />
very good article. But I found two liitle errors:<br />
1.) Your function get_word_features() does only need one argument.<br />
2.)apply_features() needs to be called upon  nltk.classify.util instead of only nltk.classify</p>
<p>Thanks for sharing.</p>
						<p class="commentmetadata"><a href="#comment-10097" title="">Link</a> | January 3rd, 2012 at 4:40 am </p>
		</li>
					<li class="alt" id="comment-10103">
			<p><img alt='' src='http://1.gravatar.com/avatar/fc754f70f57f109902e8ba61c99eb184?s=32&amp;d=http%3A%2F%2F1.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D32&amp;r=G' class='avatar avatar-32 photo' height='32' width='32' /><cite><a href='http://tuxcoder.wordpress.com' rel='external nofollow' class='url'>Arulalan.T</a></cite> wrote:</p>
			<p>Thanks a lot. Very very useful coding stuff.</p>
						<p class="commentmetadata"><a href="#comment-10103" title="">Link</a> | January 3rd, 2012 at 6:12 am </p>
		</li>
					<li class="" id="comment-10118">
			<p><img alt='' src='http://1.gravatar.com/avatar/7605fb32400453068c5d5932f11c5e2a?s=32&amp;d=http%3A%2F%2F1.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D32&amp;r=G' class='avatar avatar-32 photo' height='32' width='32' /><cite>Elliott</cite> wrote:</p>
			<p>Really great article ! You say in the real implementation, you use around 1200 tweets; is there a GUI, or is it possible to automate the process of adding all these tweets into their respective lists? It just seems kind of long to have to do it by hand.</p>
						<p class="commentmetadata"><a href="#comment-10118" title="">Link</a> | January 3rd, 2012 at 9:36 am </p>
		</li>
					<li class="alt" id="comment-10134">
			<p><img alt='' src='http://0.gravatar.com/avatar/85abe641742822334610140d3092958f?s=32&amp;d=http%3A%2F%2F0.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D32&amp;r=G' class='avatar avatar-32 photo' height='32' width='32' /><cite>Hywel M</cite> wrote:</p>
			<p>Thanks very much. Excellent timing for me as I was looking how to do this &#8211; but with Welsh language tweets. On a quick read I haven&#8217;t spotted anything that limits this to working only with English &#8211; or have I missed anything?</p>
						<p class="commentmetadata"><a href="#comment-10134" title="">Link</a> | January 3rd, 2012 at 1:34 pm </p>
		</li>
					<li class="" id="comment-10167">
			<p><img alt='' src='http://0.gravatar.com/avatar/2cede663a8d43f6038c010fea7f68e6c?s=32&amp;d=http%3A%2F%2F0.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D32&amp;r=G' class='avatar avatar-32 photo' height='32' width='32' /><cite>mark</cite> wrote:</p>
			<p>very nice posting! it makes me wondering what else is possible. i&#8217;ll definitely add your blog to my blogroll.</p>
						<p class="commentmetadata"><a href="#comment-10167" title="">Link</a> | January 4th, 2012 at 6:14 am </p>
		</li>
					<li class="alt" id="comment-10242">
			<p><img alt='' src='http://0.gravatar.com/avatar/85abe641742822334610140d3092958f?s=32&amp;d=http%3A%2F%2F0.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D32&amp;r=G' class='avatar avatar-32 photo' height='32' width='32' /><cite>Hywel M</cite> wrote:</p>
			<p>Excellent guide. Just what I was looking for as I&#8217;m just starting to explore sentiment analysis. Thanks very much.</p>
<p>I can&#8217;t see what &#8216;num_word_features&#8217; is doing in the 3rd line of code under Classifier.</p>
						<p class="commentmetadata"><a href="#comment-10242" title="">Link</a> | January 5th, 2012 at 5:00 pm </p>
		</li>
					<li class="authorpost" id="comment-10328">
			<p><img alt='' src='http://0.gravatar.com/avatar/a37d0d4170a049c8e4e34c1c34ea8ca6?s=32&amp;d=http%3A%2F%2F0.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D32&amp;r=G' class='avatar avatar-32 photo' height='32' width='32' /><cite>Laurent Luce</cite> wrote:</p>
			<p>@Patrick Thanks for the feedback. I fixed the call to get_word_features(). Regarding apply_features, it says nltk.classify.apply_features in the nltk online book: <a href="http://nltk.googlecode.com/svn/trunk/doc/book/ch06.html" rel="nofollow">http://nltk.googlecode.com/svn/trunk/doc/book/ch06.html</a>. It has been working for me so I am not sure what might have changed.</p>
						<p class="commentmetadata"><a href="#comment-10328" title="">Link</a> | January 7th, 2012 at 10:53 am </p>
		</li>
					<li class="authorpost" id="comment-10329">
			<p><img alt='' src='http://0.gravatar.com/avatar/a37d0d4170a049c8e4e34c1c34ea8ca6?s=32&amp;d=http%3A%2F%2F0.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D32&amp;r=G' class='avatar avatar-32 photo' height='32' width='32' /><cite>Laurent Luce</cite> wrote:</p>
			<p>@Elliott I built a simple web interface to help me classifying the tweets. I also stored the tweets in a Redis DB in 2 different lists: positive and negative. For the article, I am using hard coded list to simplify things.</p>
						<p class="commentmetadata"><a href="#comment-10329" title="">Link</a> | January 7th, 2012 at 10:55 am </p>
		</li>
					<li class="authorpost" id="comment-10330">
			<p><img alt='' src='http://0.gravatar.com/avatar/a37d0d4170a049c8e4e34c1c34ea8ca6?s=32&amp;d=http%3A%2F%2F0.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D32&amp;r=G' class='avatar avatar-32 photo' height='32' width='32' /><cite>Laurent Luce</cite> wrote:</p>
			<p>@Hywel You are correct. The same can apply to other languages. I am actually using that method to classify tweets written in French. I am not satisfied with the results yet because the sample I classified manually is too small. An issue with other languages than English is that it is difficult to find a large corpus of classified tweets.</p>
						<p class="commentmetadata"><a href="#comment-10330" title="">Link</a> | January 7th, 2012 at 11:08 am </p>
		</li>
					<li class="authorpost" id="comment-10331">
			<p><img alt='' src='http://0.gravatar.com/avatar/a37d0d4170a049c8e4e34c1c34ea8ca6?s=32&amp;d=http%3A%2F%2F0.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D32&amp;r=G' class='avatar avatar-32 photo' height='32' width='32' /><cite>Laurent Luce</cite> wrote:</p>
			<p>@ Hywel I fixed the call to get_word_features. I am trimming the number of word features in the real application but I keep it simpler for the post.</p>
						<p class="commentmetadata"><a href="#comment-10331" title="">Link</a> | January 7th, 2012 at 11:13 am </p>
		</li>
					<li class="alt" id="comment-10335">
			<p><img alt='' src='http://1.gravatar.com/avatar/7605fb32400453068c5d5932f11c5e2a?s=32&amp;d=http%3A%2F%2F1.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D32&amp;r=G' class='avatar avatar-32 photo' height='32' width='32' /><cite>Elliott</cite> wrote:</p>
			<p>@Laurent Luce The web interface is quite a good idea. If anyone is looking for a pre-classified test corpus, I found one here: <a href="http://sandersanalytics.com/lab/twitter-sentiment/" rel="nofollow">http://sandersanalytics.com/lab/twitter-sentiment/</a>.</p>
						<p class="commentmetadata"><a href="#comment-10335" title="">Link</a> | January 7th, 2012 at 3:53 pm </p>
		</li>
					<li class="authorpost" id="comment-10677">
			<p><img alt='' src='http://0.gravatar.com/avatar/a37d0d4170a049c8e4e34c1c34ea8ca6?s=32&amp;d=http%3A%2F%2F0.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D32&amp;r=G' class='avatar avatar-32 photo' height='32' width='32' /><cite>Laurent Luce</cite> wrote:</p>
			<p>@Elliott Thanks for the link to that pre-classified test corpus. Here is another one using emoticons: <a href="http://www.stanford.edu/~alecmgo/cs224n/twitterdata.2009.05.25.c.zip" rel="nofollow">http://www.stanford.edu/~alecmgo/cs224n/twitterdata.2009.05.25.c.zip</a><br />
I had to manually classified the tweets on my side because they are in French and I didn&#8217;t find a pre-classified corpus in French.</p>
						<p class="commentmetadata"><a href="#comment-10677" title="">Link</a> | January 14th, 2012 at 11:12 am </p>
		</li>
					<li class="alt" id="comment-10700">
			<p><img alt='' src='http://1.gravatar.com/avatar/7605fb32400453068c5d5932f11c5e2a?s=32&amp;d=http%3A%2F%2F1.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D32&amp;r=G' class='avatar avatar-32 photo' height='32' width='32' /><cite>Elliott</cite> wrote:</p>
			<p>@Laurent Luce Pour les liens en français, je sais que ça peut sembler un peu arbitraire, mais prendre un corpus en anglais et le faire passer par Google Translate, je vois pas de raison pour que ça marche pas!</p>
						<p class="commentmetadata"><a href="#comment-10700" title="">Link</a> | January 14th, 2012 at 9:48 pm </p>
		</li>
					<li class="" id="comment-12042">
			<p><img alt='' src='http://1.gravatar.com/avatar/d0732006e77cba51c6fa3c5369f0474c?s=32&amp;d=http%3A%2F%2F1.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D32&amp;r=G' class='avatar avatar-32 photo' height='32' width='32' /><cite>Ultraviolet</cite> wrote:</p>
			<p>Very useful Laurent! thanks for your post</p>
						<p class="commentmetadata"><a href="#comment-12042" title="">Link</a> | February 18th, 2012 at 3:25 pm </p>
		</li>
					<li class="alt" id="comment-12882">
			<p><img alt='' src='http://1.gravatar.com/avatar/380fd69e59ebe4c8797d183926e61dd4?s=32&amp;d=http%3A%2F%2F1.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D32&amp;r=G' class='avatar avatar-32 photo' height='32' width='32' /><cite><a href='http://Student' rel='external nofollow' class='url'>Phil Day</a></cite> wrote:</p>
			<p>Thanks so much for this, great blog. <img src="http://www.laurentluce.com/wp-includes/images/smilies/icon_smile.gif" alt=":)" class="wp-smiley" /> </p>
						<p class="commentmetadata"><a href="#comment-12882" title="">Link</a> | March 7th, 2012 at 1:24 pm </p>
		</li>
					<li class="" id="comment-13657">
			<p><img alt='' src='http://0.gravatar.com/avatar/e9b83e97abee86458281104254b74224?s=32&amp;d=http%3A%2F%2F0.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D32&amp;r=G' class='avatar avatar-32 photo' height='32' width='32' /><cite>Luca</cite> wrote:</p>
			<p>The algorithm used by NLTK is highly inefficient. With about 9000 positive tweets and 9000 negative tweets on a 8gb ram quad core server (2ghz each) it takes 45 minutes to be trained (running on pypy). I highly suggest to write your own implementation of the Baesian Classifier; mine takes about 1.5 minutes to train with 9000/9000 tweets on the same machine.</p>
						<p class="commentmetadata"><a href="#comment-13657" title="">Link</a> | March 13th, 2012 at 11:51 am </p>
		</li>
					<li class="alt" id="comment-15200">
			<p><img alt='' src='http://1.gravatar.com/avatar/d79e34c362b10a0e98bdae7af2fdfaa0?s=32&amp;d=http%3A%2F%2F1.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D32&amp;r=G' class='avatar avatar-32 photo' height='32' width='32' /><cite>Mark</cite> wrote:</p>
			<p>What would be a reasonable number of manually classified tweets to use in order to train the classifier in a real world system? </p>
<p>Would there be a point at which manually training more tweets becomes pointless or detrimental?</p>
						<p class="commentmetadata"><a href="#comment-15200" title="">Link</a> | March 26th, 2012 at 4:02 am </p>
		</li>
					<li class="" id="comment-16683">
			<p><img alt='' src='http://0.gravatar.com/avatar/eed3da94be943b41248eefbf2c8d0a7f?s=32&amp;d=http%3A%2F%2F0.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D32&amp;r=G' class='avatar avatar-32 photo' height='32' width='32' /><cite><a href='http://ravikiranj.net' rel='external nofollow' class='url'>Ravikiran Janardhana</a></cite> wrote:</p>
			<p>The clarity of your post and the brilliant explanation is just amazing ! Great work Sir <img src="http://www.laurentluce.com/wp-includes/images/smilies/icon_smile.gif" alt=":)" class="wp-smiley" />  !</p>
						<p class="commentmetadata"><a href="#comment-16683" title="">Link</a> | April 15th, 2012 at 8:19 am </p>
		</li>
					<li class="alt" id="comment-19253">
			<p><img alt='' src='http://1.gravatar.com/avatar/fb17bfd4839f84012ed83914b619c579?s=32&amp;d=http%3A%2F%2F1.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D32&amp;r=G' class='avatar avatar-32 photo' height='32' width='32' /><cite><a href='http://arbiesamong.com' rel='external nofollow' class='url'>Arbie Samong</a></cite> wrote:</p>
			<p>For those getting the error<br />
nltk.classify has no module apply_features</p>
<p>make sure your nltk version is correct:<br />
PyYAML==3.09<br />
nltk==2.0.1rc1</p>
						<p class="commentmetadata"><a href="#comment-19253" title="">Link</a> | May 11th, 2012 at 4:01 am </p>
		</li>
					<li class="authorpost" id="comment-21984">
			<p><img alt='' src='http://0.gravatar.com/avatar/a37d0d4170a049c8e4e34c1c34ea8ca6?s=32&amp;d=http%3A%2F%2F0.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D32&amp;r=G' class='avatar avatar-32 photo' height='32' width='32' /><cite>Laurent Luce</cite> wrote:</p>
			<p>@Mark. There are few papers out there on training sets. Size of 200k-300k is not uncommon. Not sure where the upper limit is.</p>
						<p class="commentmetadata"><a href="#comment-21984" title="">Link</a> | June 1st, 2012 at 6:09 pm </p>
		</li>
					<li class="alt" id="comment-22843">
			<p><img alt='' src='http://0.gravatar.com/avatar/6f3b407df026f579ac1d2aeaa4e60910?s=32&amp;d=http%3A%2F%2F0.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D32&amp;r=G' class='avatar avatar-32 photo' height='32' width='32' /><cite>Ana</cite> wrote:</p>
			<p>Hi&#8230;it&#8217;s great explanation. Thanks for sharing&#8230;</p>
<p>Right now I&#8217;m working in this kind of work, and having great challenge in converting tweet language to standard form. Any advice? Thanks <img src="http://www.laurentluce.com/wp-includes/images/smilies/icon_smile.gif" alt=":)" class="wp-smiley" /> </p>
						<p class="commentmetadata"><a href="#comment-22843" title="">Link</a> | June 10th, 2012 at 9:40 am </p>
		</li>
					<li class="" id="comment-25510">
			<p><img alt='' src='http://0.gravatar.com/avatar/e4bfc703c2ecbf1fa2eb5f62e80a7859?s=32&amp;d=http%3A%2F%2F0.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D32&amp;r=G' class='avatar avatar-32 photo' height='32' width='32' /><cite>Thiago</cite> wrote:</p>
			<p>Thanks a lot for the tutorial. I followed it with some modifications for my purpose. But, like Luca wrote, it&#8217;s very inefficient, but it works efficiently. With your base I got 0.81 of accuracy. With a movie review database I got an 0.77. And with another tweet database selected by my group I got a lot less: 0,69 of accuracy. I calculated these accuracy using a 3-fold cross validation.</p>
						<p class="commentmetadata"><a href="#comment-25510" title="">Link</a> | July 2nd, 2012 at 10:39 am </p>
		</li>
					<li class="alt" id="comment-30812">
			<p><img alt='' src='http://1.gravatar.com/avatar/f29e862e012e69cf44a2380d17961313?s=32&amp;d=http%3A%2F%2F1.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D32&amp;r=G' class='avatar avatar-32 photo' height='32' width='32' /><cite>Jaimin</cite> wrote:</p>
			<p>Very good information, and detailed explanation. Thanks for sharing it.</p>
						<p class="commentmetadata"><a href="#comment-30812" title="">Link</a> | September 3rd, 2012 at 7:37 pm </p>
		</li>
					<li class="" id="comment-31544">
			<p><img alt='' src='http://0.gravatar.com/avatar/e537ce1e3e38b22103cbbcf69015c700?s=32&amp;d=http%3A%2F%2F0.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D32&amp;r=G' class='avatar avatar-32 photo' height='32' width='32' /><cite>Pramod Gupta</cite> wrote:</p>
			<p>Hi Laurent,</p>
<p>Can you please let me know some good references for Sentiment Analysis especially implementation issues e.g., choosing word features, feature extractions etc.</p>
<p>Thanks</p>
						<p class="commentmetadata"><a href="#comment-31544" title="">Link</a> | September 13th, 2012 at 2:25 pm </p>
		</li>
					<li class="alt" id="comment-31604">
			<p><img alt='' src='http://1.gravatar.com/avatar/5c3225273894362eb0f6372723ea3e8b?s=32&amp;d=http%3A%2F%2F1.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D32&amp;r=G' class='avatar avatar-32 photo' height='32' width='32' /><cite><a href='http://thinknook.com' rel='external nofollow' class='url'>Links</a></cite> wrote:</p>
			<p>This is a really great walk through of sentiment classification using NLTK (especially since my Python skills are non-existent), thanks for sharing Laurent!</p>
<p>Just an FYI- the apply_features function seems to be really slow for a large number of tweets (e.g. 100,000 tweets have taken over 12 hours and still running). any tips to improve the performance?, this is not even half of my training set!</p>
						<p class="commentmetadata"><a href="#comment-31604" title="">Link</a> | September 14th, 2012 at 1:24 am </p>
		</li>
					<li class="" id="comment-32400">
			<p><img alt='' src='http://0.gravatar.com/avatar/cde44c4be4e82e1f8ac1076d48999863?s=32&amp;d=http%3A%2F%2F0.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D32&amp;r=G' class='avatar avatar-32 photo' height='32' width='32' /><cite>Deyan</cite> wrote:</p>
			<p>I don&#8217;t understand.What is the purpose of test_tweets??</p>
						<p class="commentmetadata"><a href="#comment-32400" title="">Link</a> | September 24th, 2012 at 6:02 am </p>
		</li>
					<li class="authorpost" id="comment-34564">
			<p><img alt='' src='http://0.gravatar.com/avatar/a37d0d4170a049c8e4e34c1c34ea8ca6?s=32&amp;d=http%3A%2F%2F0.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D32&amp;r=G' class='avatar avatar-32 photo' height='32' width='32' /><cite>Laurent Luce</cite> wrote:</p>
			<p>@Deyan: test_tweets is our manually classified list of tuples: words + positive/negative.</p>
						<p class="commentmetadata"><a href="#comment-34564" title="">Link</a> | October 16th, 2012 at 9:20 am </p>
		</li>
					<li class="alt" id="comment-34933">
			<p><img alt='' src='http://0.gravatar.com/avatar/0b5fcd44a0ff8f4a1bcb231cf714c1e6?s=32&amp;d=http%3A%2F%2F0.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D32&amp;r=G' class='avatar avatar-32 photo' height='32' width='32' /><cite><a href='http://bonnieyu.tumblr.com/' rel='external nofollow' class='url'>Bonnie</a></cite> wrote:</p>
			<p>nice blog ! it&#8217;s very easy to follow. I wrote my own naive bayes python classifier before but think it&#8217;s time to move on to playing with other libraries. </p>
<p>btw does the theme you&#8217;re using make it easy to share code? or did you do the highlighting yourself? I&#8217;ve been meaning to write some posts where I can share code for people.</p>
						<p class="commentmetadata"><a href="#comment-34933" title="">Link</a> | October 19th, 2012 at 11:39 am </p>
		</li>
					<li class="" id="comment-37392">
			<p><img alt='' src='http://1.gravatar.com/avatar/961cb7384e3a5b293cc897708dd246f1?s=32&amp;d=http%3A%2F%2F1.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D32&amp;r=G' class='avatar avatar-32 photo' height='32' width='32' /><cite>koda</cite> wrote:</p>
			<p>Really nice article. @luca can you share the links or blog post for your implementation ?</p>
						<p class="commentmetadata"><a href="#comment-37392" title="">Link</a> | November 9th, 2012 at 10:00 pm </p>
		</li>
					<li class="authorpost" id="comment-39196">
			<p><img alt='' src='http://0.gravatar.com/avatar/a37d0d4170a049c8e4e34c1c34ea8ca6?s=32&amp;d=http%3A%2F%2F0.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D32&amp;r=G' class='avatar avatar-32 photo' height='32' width='32' /><cite>Laurent Luce</cite> wrote:</p>
			<p>@Bonnie: I use SyntaxHighlighter Evolved.</p>
						<p class="commentmetadata"><a href="#comment-39196" title="">Link</a> | November 21st, 2012 at 7:35 am </p>
		</li>
					<li class="alt" id="comment-50043">
			<p><img alt='' src='http://0.gravatar.com/avatar/c59f9b050c7f083bc492556ce1d58498?s=32&amp;d=http%3A%2F%2F0.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D32&amp;r=G' class='avatar avatar-32 photo' height='32' width='32' /><cite>jutky</cite> wrote:</p>
			<p>Very helpful article.<br />
Helped me to solve exactly the problem I had.</p>
						<p class="commentmetadata"><a href="#comment-50043" title="">Link</a> | January 8th, 2013 at 3:59 am </p>
		</li>
					<li class="" id="comment-61655">
			<p><img alt='' src='http://0.gravatar.com/avatar/6bc6b685213aab22b862af435ad2a9af?s=32&amp;d=http%3A%2F%2F0.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D32&amp;r=G' class='avatar avatar-32 photo' height='32' width='32' /><cite><a href='http://www.engineeringduniya.com' rel='external nofollow' class='url'>EngineeringDuniya</a></cite> wrote:</p>
			<p>Really useful article!</p>
						<p class="commentmetadata"><a href="#comment-61655" title="">Link</a> | March 3rd, 2013 at 1:24 pm </p>
		</li>
					<li class="alt" id="comment-94695">
			<p><img alt='' src='http://0.gravatar.com/avatar/631fd10be02d711a3c4f95c1aacb2778?s=32&amp;d=http%3A%2F%2F0.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D32&amp;r=G' class='avatar avatar-32 photo' height='32' width='32' /><cite>Andrew Martin</cite> wrote:</p>
			<p>Thanks for this excellent tutorial. I do have to ask though, is there an alternative to the classifier you use? I tried using it, but my dataset is 1.5 million tweets and I just don&#8217;t think it&#8217;s feasible. It&#8217;s taking far too long.<br />
Is there other ready-build libraries you know of that I could substitute?</p>
						<p class="commentmetadata"><a href="#comment-94695" title="">Link</a> | August 9th, 2013 at 3:45 pm </p>
		</li>
					<li class="" id="comment-345791">
			<p><img alt='' src='http://1.gravatar.com/avatar/991592e76c5d47eca75549b559388932?s=32&amp;d=http%3A%2F%2F1.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D32&amp;r=G' class='avatar avatar-32 photo' height='32' width='32' /><cite>Eduard</cite> wrote:</p>
			<p>Thanks.<br />
You are inspiring me for writing my bachelor degree project.</p>
						<p class="commentmetadata"><a href="#comment-345791" title="">Link</a> | May 9th, 2014 at 6:04 pm </p>
		</li>
					<li class="alt" id="comment-345801">
			<p><img alt='' src='http://0.gravatar.com/avatar/61bef210e0832636c300f3c75d071858?s=32&amp;d=http%3A%2F%2F0.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D32&amp;r=G' class='avatar avatar-32 photo' height='32' width='32' /><cite>Paulo Oliveira</cite> wrote:</p>
			<p>Hi Laurent</p>
<p>Is there a corpus of classified tweets in Brazilian Portuguese?</p>
<p>Thanks in advance.</p>
<p>Paulo</p>
						<p class="commentmetadata"><a href="#comment-345801" title="">Link</a> | May 19th, 2014 at 7:42 am </p>
		</li>
		</ol>
		
<h3 id="respond">Leave Your Comment</h3>
		<form action="http://www.laurentluce.com/wp-comments-post.php" method="post" id="commentform">
					<p><input type="text" name="author" id="author" value="" size="22" tabindex="1" />
			<label for="author"><small>Name (required)</small></label></p>
			
			<p><input type="text" name="email" id="email" value="" size="22" tabindex="2" />
			<label for="email"><small>Mail (will not be published) (required)</small></label></p>
			
			<p><input type="text" name="url" id="url" value="" size="22" tabindex="3" />
			<label for="url"><small>Website</small></label></p>
				<!-- to show commenters which tags are allowed, uncomment the line below. -->
		<!--<p><strong>Allowed (X)HTML:</strong> &lt;a href=&quot;&quot; title=&quot;&quot;&gt; &lt;abbr title=&quot;&quot;&gt; &lt;acronym title=&quot;&quot;&gt; &lt;b&gt; &lt;blockquote cite=&quot;&quot;&gt; &lt;cite&gt; &lt;code&gt; &lt;del datetime=&quot;&quot;&gt; &lt;em&gt; &lt;i&gt; &lt;q cite=&quot;&quot;&gt; &lt;strike&gt; &lt;strong&gt; </p>-->
		<textarea name="comment" id="comment" cols="50" rows="10" tabindex="4"></textarea>
		<p><input name="submit" type="submit" id="submit" tabindex="5" value="Post Comment" /></p>
		<input type="hidden" name="comment_post_ID" value="321" />
		<p style="display: none;"><input type="hidden" id="akismet_comment_nonce" name="akismet_comment_nonce" value="ea9fa8612d" /></p><script type='text/javascript' src='http://www.laurentluce.com/wp-content/plugins/akismet/_inc/form.js?ver=3.0.0'></script>
<p style="display: none;"><input type="hidden" id="ak_js" name="ak_js" value="126"/></p>	</form>

</div><!-- end comment wrap --></div>
</div>
</div>
<div id="ft">
<script type='text/javascript' src='http://www.laurentluce.com/wp-content/plugins/syntaxhighlighter/syntaxhighlighter2/scripts/shCore.js?ver=2.1.364'></script>
<script type='text/javascript' src='http://www.laurentluce.com/wp-content/plugins/syntaxhighlighter/syntaxhighlighter2/scripts/shBrushPython.js?ver=2.1.364'></script>
<script type='text/javascript'>
	(function(){
		var corecss = document.createElement('link');
		var themecss = document.createElement('link');
		var corecssurl = "http://www.laurentluce.com/wp-content/plugins/syntaxhighlighter/syntaxhighlighter2/styles/shCore.css?ver=2.1.364";
		if ( corecss.setAttribute ) {
				corecss.setAttribute( "rel", "stylesheet" );
				corecss.setAttribute( "type", "text/css" );
				corecss.setAttribute( "href", corecssurl );
		} else {
				corecss.rel = "stylesheet";
				corecss.href = corecssurl;
		}
		document.getElementsByTagName("head")[0].insertBefore( corecss, document.getElementById("syntaxhighlighteranchor") );
		var themecssurl = "http://www.laurentluce.com/wp-content/plugins/syntaxhighlighter/syntaxhighlighter2/styles/shThemeEclipse.css?ver=2.1.364";
		if ( themecss.setAttribute ) {
				themecss.setAttribute( "rel", "stylesheet" );
				themecss.setAttribute( "type", "text/css" );
				themecss.setAttribute( "href", themecssurl );
		} else {
				themecss.rel = "stylesheet";
				themecss.href = themecssurl;
		}
		//document.getElementById("syntaxhighlighteranchor").appendChild(themecss);
		document.getElementsByTagName("head")[0].insertBefore( themecss, document.getElementById("syntaxhighlighteranchor") );
	})();
	SyntaxHighlighter.config.clipboardSwf = 'http://www.laurentluce.com/wp-content/plugins/syntaxhighlighter/syntaxhighlighter2/scripts/clipboard.swf';
	SyntaxHighlighter.config.strings.expandSource = 'show source';
	SyntaxHighlighter.config.strings.viewSource = 'view source';
	SyntaxHighlighter.config.strings.copyToClipboard = 'copy to clipboard';
	SyntaxHighlighter.config.strings.copyToClipboardConfirmation = 'The code is in your clipboard now';
	SyntaxHighlighter.config.strings.print = 'print';
	SyntaxHighlighter.config.strings.help = '?';
	SyntaxHighlighter.config.strings.alert = 'SyntaxHighlighter\n\n';
	SyntaxHighlighter.config.strings.noBrush = 'Can\'t find brush for: ';
	SyntaxHighlighter.config.strings.brushNotHtmlScript = 'Brush wasn\'t configured for html-script option: ';
	SyntaxHighlighter.defaults['pad-line-numbers'] = true;
	SyntaxHighlighter.all();
</script>
</div>
</div><!-- End id=doc -->
</div><!-- End id=wrapper -->
<div class="clear">&nbsp;</div>
<div id="footnote" align="center">
	Powered by <a href="http://wordpress.org/">Wordpress</a> and <a href="http://www.mysql.com/">MySQL</a>. Theme by <a href="http://code.openark.org/blog/shlomi-noach">Shlomi Noach</a>, <a href="http://openark.org">openark.org</a>
</div>
</div><!-- End align=center -->
</body>
</html>
